{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Check these before running\n",
    "\n",
    "# Finn's Laptop\n",
    "studydir = '/mnt/s/Research/Projects/KPUM_NODDI/Data'\n",
    "niftibasefolder = 'nifti' # nifti basefolder to go within studydir\n",
    "codedir = os.path.join(studydir,'code/kpum_noddi')\n",
    "datadirbasefolder = 'derivatives/dMRI_OrigProtocol'\n",
    "protocol = 'ORIG' # 'NEW'\n",
    "\n",
    "# KPUM Workstation\n",
    "#studydir = '/mnt/e/Research/Projects/KPUM_NODDI/Data'\n",
    "#niftibasefolder = 'nifti' # nifti basefolder to go within studydir\n",
    "#codedir = os.path.join('home/radio/KPUM_NODDI','code/kpum_noddi')\n",
    "#datadirbasefolder = 'derivatives/dMRI_OrigProtocol'\n",
    "#protocol = 'ORIG' # 'NEW'\n",
    "\n",
    "# tsv-files to keep track of in studydir/niftibasefolder\n",
    "subjecttrackerpath = os.path.join(studydir, datadirbasefolder)\n",
    "subjecttrackerfile = 'Subject_Tracker_for_dmri_pipeline.tsv'\n",
    "\n",
    "###################################################################################\n",
    "# USER INPUT\n",
    "\n",
    "# Participant details\n",
    "subject = '023'\n",
    "session = 'MR1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "# Define I/O folders and files\n",
    "niftifolder = os.path.join(studydir, niftibasefolder, os.path.join(f'sub-{subject}',f'ses-{session}'))\n",
    "datadir = os.path.join(studydir, datadirbasefolder,  os.path.join(f'sub-{subject}',f'ses-{session}'))\n",
    "if not os.path.exists(datadir): # then make this directory\n",
    "    os.makedirs(datadir)\n",
    "subjecttrackertsv = os.path.join(subjecttrackerpath, subjecttrackerfile)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process to perform dmri_prepare_pipeline\n",
      "Status for dmri_prepare_pipeline is set to Pending = need to do this step\n",
      "Preparing for dMRI pipeline\n",
      "Subject:           023\n",
      "Session:           MR1\n",
      "Session file:      nifti/sub-023/ses-MR1/session_QC.tsv\n",
      "Data directory:    /mnt/s/Research/Projects/KPUM_NODDI/Data/derivatives/dMRI_OrigProtocol/sub-023/ses-MR1\n",
      "\n",
      "/mnt/s/Research/Projects/KPUM_NODDI/Data/code/kpum_noddi/shell/dmri_prepare_pipeline.sh       023 MR1 -d /mnt/s/Research/Projects/KPUM_NODDI/Data/derivatives/dMRI_OrigProtocol/sub-023/ses-MR1\n",
      "----------------------------\n",
      "dMRI preprocessing on subject 023 and session MR1\n",
      "\n",
      "Transfer data in nifti/sub-023/ses-MR1/session_QC.tsv which has qc_pass_fail = 1 or 0.5\n",
      "Status for dmri_prepare_pipeline is set to Done\n",
      "\n",
      "Process to perform dmri_preprocess\n",
      "Status for dmri_preprocess is set to Pending = need to do this step\n",
      "dMRI preprocessing\n",
      "Subject:       \t023\n",
      "Session:        MR1\n",
      "Session file:\t/mnt/s/Research/Projects/KPUM_NODDI/Data/derivatives/dMRI_OrigProtocol/sub-023/ses-MR1/session_QC.tsv\n",
      "DWI (AP):\n",
      "MRI Protocol:\tORIG\n",
      "Threads:\t4\n",
      "DataDirectory:\t/mnt/s/Research/Projects/KPUM_NODDI/Data/derivatives/dMRI_OrigProtocol/sub-023/ses-MR1\n",
      "\n",
      "/mnt/s/Research/Projects/KPUM_NODDI/Data/code/kpum_noddi/shell/dmri_preprocess.sh   \t023 MR1 -d /mnt/s/Research/Projects/KPUM_NODDI/Data/derivatives/dMRI_OrigProtocol/sub-023/ses-MR1 -protocol ORIG -s /mnt/s/Research/Projects/KPUM_NODDI/Data/derivatives/dMRI_OrigProtocol/sub-023/ses-MR1/session_QC.tsv -threads 4\n",
      "----------------------------\n",
      "dMRI preprocessing on subject 023 and session MR1\n",
      "\n",
      "Reading /mnt/s/Research/Projects/KPUM_NODDI/Data/derivatives/dMRI_OrigProtocol/sub-023/ses-MR1/session_QC.tsv and use entries to create relevant files\n",
      "We have ORIG protocol\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mrconvert: [100%] copying from \"/mnt/s/Res...-023_ses-MR1_dir-AP_dwi.nii\" to \"/mnt/s/Res...1/dwi/preproc/tmp_dwiAP.mif\"\u001b[0K[0K\u001b[?7h\u001b[?7l\u001b[?7l\u001b[?7l\u001b[?7l\n",
      "dwiextract: [100%] extracting volumes\u001b[0K[0K\u001b[?7h\u001b[?7l\u001b[?7l\u001b[?7l\u001b[?7l\u001b[?7l\u001b[?7l\u001b[?7l\n",
      "dwiextract: [100%] extracting volumes\u001b[0K[0K\u001b[?7h\u001b[?7l\n",
      "mrconvert: [100%] copying from \"/tmp/mrtrix-tmp-GaaskD.mif\" to \"/mnt/s/Res...wi/preproc/tmp_dwiAP_b0.mif\"\u001b[0K[0K\u001b[?7h\u001b[?7l\n",
      "mrcat: [100%] concatenating \"/mnt/s/Research/Projects/KPUM_NODDI/Data/derivatives/dMRI_OrigProtocol/sub-023/ses-MR1/dwi/preproc/tmp_dwiAP_b0.mif\"\u001b[0K[0K\u001b[?7h\u001b[?7l\u001b[?7l\n",
      "mrcat: [100%] concatenating \"/mnt/s/Research/Projects/KPUM_NODDI/Data/derivatives/dMRI_OrigProtocol/sub-023/ses-MR1/dwi/preproc/tmp_dwiAP_b1000b2000.mif\"\u001b[0K[0K\u001b[?7h\u001b[?7l\u001b[?7l\u001b[?7l\u001b[?7l\u001b[?7l\u001b[?7l\u001b[?7l\n",
      "mrconvert: [100%] copying from \"/mnt/s/Res...-023_ses-MR1_dir-AP_dwi.nii\" to \"/tmp/mrtrix-tmp-rWt14e.mif\"\u001b[0K[0K\u001b[?7h\u001b[?7l\u001b[?7l\u001b[?7l\n",
      "mrconvert: [100%] copying from \"/tmp/mrtrix-tmp-rWt14e.mif\" to \"/mnt/s/Res.../dwi/preproc/topup/b0AP.mif\"\u001b[0K[0K\u001b[?7h\u001b[?7l\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We only have b0AP.mif in /topup => do not have a fieldmap, so eddy will be run without a TOPUP fieldmap\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "mrconvert: [100%] copying from \"dwiAP.mif\" to \"dwi.mif\"\u001b[0K[0K\u001b[?7h\u001b[?7l\u001b[?7l\u001b[?7l\u001b[?7l\u001b[?7l\u001b[?7l\u001b[?7l\u001b[?7l\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doing MP PCA-denosing with dwidenoise\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "dwidenoise: [100%] preloading data for \"dwi.mif\"\u001b[0K[0K\u001b[?7h\u001b[?7l\u001b[?7l\u001b[?7l\u001b[?7l\u001b[?7l\u001b[?7l\u001b[?7l\u001b[?7l\n",
      "dwidenoise: [ 24%] running MP-PCA denoising...\u001b[0K\u001b[?7h\u001b[?7l\u001b[?7l\u001b[?7l\u001b[?7l\u001b[?7l\u001b[?7l\u001b[?7l\u001b[?7l\u001b[?7l\u001b[?7l\u001b[?7l\u001b[?7l\u001b[?7l\u001b[?7l\u001b[?7l\u001b[?7l\u001b[?7l\u001b[?7l\u001b[?7l\u001b[?7l\u001b[?7l\u001b[?7l\u001b[?7l\u001b[?7l"
     ]
    }
   ],
   "source": [
    "######################################\n",
    "# Define local functions\n",
    "\n",
    "def create_subjectrackertsv(subjecttrackertsv, subject, session) :   \n",
    "    import os \n",
    "    import pandas as pd\n",
    "    # create dataframe and write to file\n",
    "    new_row = {'participant_id': [f'sub-{subject}'], \n",
    "            'session_id': [f'ses-{session}']} \n",
    "    df = pd.DataFrame(new_row)\n",
    "    df.to_csv(subjecttrackertsv, sep=\"\\t\", index=False)\n",
    "\n",
    "def add_rowtodataframe(df, subject, session) :\n",
    "    import pandas as pd\n",
    "    # Check if {subject} {session} has entry in DataFrame, and adds if not\n",
    "    if not ((df['participant_id'] == f'sub-{subject}') & (df['session_id'] == f'ses-{session}')).any() :\n",
    "        # Add as a new line at the bottom\n",
    "        df = pd.concat([df, *[df.tail(1)]*1], ignore_index=True) # duplicates the last row in df\n",
    "        # first set all columns in the new last row to ''\n",
    "        df.loc[df.index[-1],:] = ''\n",
    "        # then update with correct subject and session\n",
    "        df.loc[df.index[-1],'participant_id'] = f'sub-{subject}'\n",
    "        df.loc[df.index[-1],'session_id'] = f'ses-{session}'\n",
    "    return df\n",
    "\n",
    "def insert_process(df, process) :\n",
    "    import pandas as pd\n",
    "    # Check if process is in any of the df.columns\n",
    "    # if not include put\n",
    "    if not process in df.columns :\n",
    "        # insert \"process\" and \"process comments\" columns add new two last columnsS\n",
    "        df.insert(loc=len(df.columns), column=process, value='')\n",
    "        df.insert(loc=len(df.columns), column=process+' comments', value='')\n",
    "    return df\n",
    "\n",
    "def checkstatus_process(df, process, subject, session, status) :\n",
    "    import pandas as pd\n",
    "    # Check the status of process for {subject} {session}\n",
    "    outputboolean = df.loc[(df['participant_id'] == f'sub-{subject}') & (df['session_id'] == f'ses-{session}'), process ].eq(status).any()\n",
    "    return outputboolean\n",
    "\n",
    "def setstatus_process(df, process, subject, session, status) :\n",
    "    import pandas as pd\n",
    "    # Check the status of process for {subject} {session}\n",
    "    df.loc[(df['participant_id'] == f'sub-{subject}') & (df['session_id'] == f'ses-{session}'), process ] = status\n",
    "    return df\n",
    "\n",
    "def perform_process(processcall) :\n",
    "    import os, subprocess\n",
    "    # Perform the process given by the processcall by launching into terminal\n",
    "    p=subprocess.Popen(processcall, stdout=subprocess.PIPE, shell=True)\n",
    "    # Poll process.stdout to show stdout live\n",
    "    while True:\n",
    "        output = p.stdout.readline()\n",
    "        if p.poll() is not None:\n",
    "            break\n",
    "        if output:\n",
    "            print(output.strip().decode(\"utf-8\"))\n",
    "    rc = p.poll()\n",
    "\n",
    "########################################\n",
    "## START\n",
    "\n",
    "import os \n",
    "import pandas as pd\n",
    "\n",
    "currdir = os.getcwd()\n",
    "os.chdir(studydir)\n",
    "\n",
    "# Read the subjecttrackertsv-file\n",
    "if not os.path.isfile(subjecttrackertsv) :\n",
    "    print(f'Creating {subjecttrackertsv}')\n",
    "    create_subjectrackertsv(subjecttrackertsv, subject, session)\n",
    "df = pd.read_csv(subjecttrackertsv, sep=\"\\t\")\n",
    "df.fillna('', inplace=True)\n",
    "\n",
    "# Check if subject session has an entry in subjecttrackertsv and add if not add one\n",
    "df = add_rowtodataframe(df, subject, session)\n",
    "\n",
    "## Process to perform - dmri_prepare_pipeline\n",
    "process = 'dmri_prepare_pipeline'\n",
    "processfile = 'dmri_prepare_pipeline.sh'\n",
    "processfilepath = os.path.join(codedir,'shell', processfile)\n",
    "processcall = f\"bash {processfilepath} {subject} {session} -d {datadir}\" \n",
    "print(f'Process to perform {process}')\n",
    "if not process in df.columns :\n",
    "    insert_process(df, process)\n",
    "# IMPORTANT - Should have a check here on whether to perform, but cannot make it work \n",
    "# Decide if we are going to perform process (i.e. Status should be Pending) and perform process\n",
    "if checkstatus_process(df, process, subject, session, 'Stop') :\n",
    "    print('We have to stop here')\n",
    "elif checkstatus_process(df, process, subject, session, 'Done') :\n",
    "    print(f'Process {process} is already Done')\n",
    "else :\n",
    "    print(f'Status for {process} is set to Pending = need to do this step')\n",
    "    setstatus_process(df, process, subject, session, 'Pending')\n",
    "    perform_process(processcall)\n",
    "    # Update status if process has gone to its end\n",
    "    if os.path.exists(os.path.join(datadir,'dwi/orig')) :\n",
    "        print(f'Status for {process} is set to Done')\n",
    "        setstatus_process(df, process, subject, session, 'Done')\n",
    "print()\n",
    "\n",
    "## Process to perform - dmri_preprocess\n",
    "process = 'dmri_preprocess'\n",
    "processfile = 'dmri_preprocess.sh'\n",
    "processfilepath = os.path.join(codedir,'shell', processfile)\n",
    "sessionQCfile = os.path.join(datadir,'session_QC.tsv')\n",
    "threads = 4\n",
    "processcall = f\"bash {processfilepath} {subject} {session} -d {datadir} -protocol {protocol} -s {sessionQCfile} -threads {threads}\" \n",
    "print(f'Process to perform {process}')\n",
    "if not process in df.columns :\n",
    "    insert_process(df, process)\n",
    "# IMPORTANT - Should have a check here on whether to perform, but cannot make it work \n",
    "# Decide if we are going to perform process (i.e. Status should be Pending) and perform process\n",
    "if checkstatus_process(df, process, subject, session, 'Stop') :\n",
    "    print('We have to stop here')\n",
    "elif checkstatus_process(df, process, subject, session, 'Done') :\n",
    "    print(f'Process {process} is already Done')\n",
    "else :\n",
    "    print(f'Status for {process} is set to Pending = need to do this step')\n",
    "    setstatus_process(df, process, subject, session, 'Pending')\n",
    "    perform_process(processcall)\n",
    "    # Update status if process has gone to its end (here last file written in /dwi)\n",
    "    if os.path.isfile(os.path.join(datadir,'dwi',f'sub-${subject}_ses-${session}_space-dwi_mask.nii')) :\n",
    "        print(f'Status for {process} is set to Done')\n",
    "        setstatus_process(df, process, subject, session, 'Done')\n",
    "print()\n",
    "\n",
    "## Process to perform - dmri_dtidk\n",
    "process = 'dmri_dtidki'\n",
    "processfile = 'dmri_dtidki.sh'\n",
    "processfilepath = os.path.join(codedir,'shell', processfile)\n",
    "dwi = os.path.join(datadir, 'dwi', f'sub-{subject}_ses-{session}_desc-preproc-inorm_dwi.mif')\n",
    "mask = os.path.join(datadir, 'dwi', f'sub-{subject}_ses-{session}_space-dwi_mask.mif')\n",
    "threads = 4\n",
    "processcall = f\"bash {processfilepath} {subject} {session} -d {datadir} -dwi {dwi} -threads {threads} -mask {mask}\" \n",
    "print(f'Process to perform {process}')\n",
    "if not process in df.columns :\n",
    "    insert_process(df, process)\n",
    "# IMPORTANT - Should have a check here on whether to perform, but cannot make it work \n",
    "# Decide if we are going to perform process (i.e. Status should be Pending) and perform process\n",
    "if checkstatus_process(df, process, subject, session, 'Stop') :\n",
    "    print('We have to stop here')\n",
    "elif checkstatus_process(df, process, subject, session, 'Done') :\n",
    "    print(f'Process {process} is already Done')\n",
    "else :\n",
    "    setstatus_process(df, process, subject, session, 'Pending')\n",
    "    perform_process(processcall)\n",
    "    # Update status if process has gone to its end (here last file written in /dwi)\n",
    "    if os.path.isfile(os.path.join(datadir,'dwi','dki',f'sub-${subject}_ses-${session}_desc-preproc-inorm_rk.nii')) :\n",
    "        print(f'Status for {process} is set to Done')\n",
    "        setstatus_process(df, process, subject, session, 'Done')\n",
    "print()\n",
    "\n",
    "# End by writing to subjecttrackertsv\n",
    "df = df.sort_values(by = 'participant_id')\n",
    "df.to_csv(subjecttrackertsv, sep=\"\\t\", index=False)\n",
    "# and back to currdir\n",
    "os.chdir(currdir)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kpum_wsl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
